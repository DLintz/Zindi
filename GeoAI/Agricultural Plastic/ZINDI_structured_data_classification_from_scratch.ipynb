{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-3cY2hlkya0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9rJ7Lb6eBVB"
   },
   "source": [
    "# Structured data classification 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xk28xBAQeBVC"
   },
   "source": [
    "### The dataset\n",
    "\n",
    "Here's the description of each feature:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gr_V8TaieBVD"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FsORTOHSeBVD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# TensorFlow is the only backend that supports string inputs.\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CWLydOlDkya3"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SEED = 2\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAd9EUgTeBVD"
   },
   "source": [
    "## Preparing the data\n",
    "\n",
    "Let's download the data and load it into a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IcWJV8KEeBVD"
   },
   "outputs": [],
   "source": [
    "Kenya = pd.read_csv(\"./Data/Kenya_training.csv\")\n",
    "Spain =  pd.read_csv(\"./Data/Spain_training.csv\")\n",
    "VNM =  pd.read_csv(\"./Data/VNM_training.csv\")\n",
    "VNM.rename(columns={'Lon': 'lon', 'Lat': 'lat'}, inplace=True) # It's to allign with the other two sources.\n",
    "\n",
    "dataframe = pd.concat([Kenya, Spain, VNM], axis=0)\n",
    "\n",
    "dataframe = dataframe.drop(['ID'], axis=1)\n",
    "dataframe['TARGET'] = dataframe['TARGET']-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fH31rLR43Ee_"
   },
   "outputs": [],
   "source": [
    "cols = dataframe.columns\n",
    "y = dataframe.pop('TARGET')\n",
    "X = dataframe\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "dataframe_test = pd.concat([X_test, y_test], axis=1)\n",
    "dataframe_test.columns = cols\n",
    "dataframe = pd.concat([X_train, y_train], axis=1)\n",
    "dataframe.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoEi90y0eBVE"
   },
   "source": [
    "The dataset includes 2825 samples with 18 columns per sample (13 features, plus the target\n",
    "label):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J4E8zGzNeBVE",
    "outputId": "2bde3b1a-8e55-47ae-adc3-c21787dcad35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1892, 15)\n",
      "Index(['lon', 'lat', 'blue_p50', 'green_p50', 'nir_p50', 'nira_p50', 're1_p50',\n",
      "       're2_p50', 're3_p50', 'red_p50', 'swir1_p50', 'swir2_p50', 'VV_p50',\n",
      "       'VH_p50', 'TARGET'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.shape)\n",
    "print(dataframe.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EZodfmLeBVE"
   },
   "source": [
    "Here's a preview of a few samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "HiR5F28leBVE",
    "outputId": "da408118-c728-4dda-df43-1103976607c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>blue_p50</th>\n",
       "      <th>green_p50</th>\n",
       "      <th>nir_p50</th>\n",
       "      <th>nira_p50</th>\n",
       "      <th>re1_p50</th>\n",
       "      <th>re2_p50</th>\n",
       "      <th>re3_p50</th>\n",
       "      <th>red_p50</th>\n",
       "      <th>swir1_p50</th>\n",
       "      <th>swir2_p50</th>\n",
       "      <th>VV_p50</th>\n",
       "      <th>VH_p50</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>108.330760</td>\n",
       "      <td>11.935960</td>\n",
       "      <td>1509.5</td>\n",
       "      <td>1681.0</td>\n",
       "      <td>3345.5</td>\n",
       "      <td>3373.0</td>\n",
       "      <td>2079.0</td>\n",
       "      <td>2881.5</td>\n",
       "      <td>3179.0</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>3360.0</td>\n",
       "      <td>2589.0</td>\n",
       "      <td>-11.054607</td>\n",
       "      <td>-17.094818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>-2.211877</td>\n",
       "      <td>36.955029</td>\n",
       "      <td>2279.0</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>3957.0</td>\n",
       "      <td>3860.0</td>\n",
       "      <td>3410.5</td>\n",
       "      <td>3571.0</td>\n",
       "      <td>3757.5</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>4274.5</td>\n",
       "      <td>3644.5</td>\n",
       "      <td>-7.130405</td>\n",
       "      <td>-13.848156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>-3.421818</td>\n",
       "      <td>36.801776</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>2631.0</td>\n",
       "      <td>4142.0</td>\n",
       "      <td>4120.5</td>\n",
       "      <td>3617.5</td>\n",
       "      <td>3965.0</td>\n",
       "      <td>4075.5</td>\n",
       "      <td>3243.0</td>\n",
       "      <td>4090.5</td>\n",
       "      <td>3516.5</td>\n",
       "      <td>-3.006588</td>\n",
       "      <td>-7.232254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>37.237998</td>\n",
       "      <td>0.075863</td>\n",
       "      <td>2762.0</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>3540.5</td>\n",
       "      <td>3812.5</td>\n",
       "      <td>3477.5</td>\n",
       "      <td>3813.0</td>\n",
       "      <td>3904.5</td>\n",
       "      <td>3074.0</td>\n",
       "      <td>4099.5</td>\n",
       "      <td>3963.0</td>\n",
       "      <td>-9.193412</td>\n",
       "      <td>-15.262289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>108.407296</td>\n",
       "      <td>12.022917</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>4227.5</td>\n",
       "      <td>4432.0</td>\n",
       "      <td>2690.5</td>\n",
       "      <td>3833.5</td>\n",
       "      <td>4339.0</td>\n",
       "      <td>2258.0</td>\n",
       "      <td>3858.0</td>\n",
       "      <td>2919.0</td>\n",
       "      <td>-5.666233</td>\n",
       "      <td>-10.101684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lon        lat  blue_p50  green_p50  nir_p50  nira_p50  re1_p50  \\\n",
       "696  108.330760  11.935960    1509.5     1681.0   3345.5    3373.0   2079.0   \n",
       "780   -2.211877  36.955029    2279.0     2705.0   3957.0    3860.0   3410.5   \n",
       "598   -3.421818  36.801776    2114.0     2631.0   4142.0    4120.5   3617.5   \n",
       "756   37.237998   0.075863    2762.0     3089.0   3540.5    3812.5   3477.5   \n",
       "217  108.407296  12.022917    2240.0     2358.0   4227.5    4432.0   2690.5   \n",
       "\n",
       "     re2_p50  re3_p50  red_p50  swir1_p50  swir2_p50     VV_p50     VH_p50  \\\n",
       "696   2881.5   3179.0   1748.0     3360.0     2589.0 -11.054607 -17.094818   \n",
       "780   3571.0   3757.5   3250.0     4274.5     3644.5  -7.130405 -13.848156   \n",
       "598   3965.0   4075.5   3243.0     4090.5     3516.5  -3.006588  -7.232254   \n",
       "756   3813.0   3904.5   3074.0     4099.5     3963.0  -9.193412 -15.262289   \n",
       "217   3833.5   4339.0   2258.0     3858.0     2919.0  -5.666233 -10.101684   \n",
       "\n",
       "     TARGET  \n",
       "696       1  \n",
       "780       1  \n",
       "598       1  \n",
       "756       1  \n",
       "217       0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ceNMm06SeBVF",
    "outputId": "c2f39357-dfaa-4fc6-949f-4f0d3f62a922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1163 samples for training and 378 for validation\n"
     ]
    }
   ],
   "source": [
    "val_dataframe = dataframe.sample(frac=0.2, random_state=2)\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    f\"Using {len(train_dataframe)} samples for training \"\n",
    "    f\"and {len(val_dataframe)} for validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-NE0S9SeBVF"
   },
   "source": [
    "Let's generate `tf.data.Dataset` objects for each dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "EdiQs5BWeBVF"
   },
   "outputs": [],
   "source": [
    "\n",
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"TARGET\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmykWW5ZeBVF"
   },
   "source": [
    "Each `Dataset` yields a tuple `(input, target)` where `input` is a dictionary of features\n",
    "and `target` is the value `0` or `1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9Ycvd62eBVF",
    "outputId": "46b1cd86-66c1-490d-b53c-0633d6811257"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'lon': <tf.Tensor: shape=(), dtype=float64, numpy=-3.000238302>, 'lat': <tf.Tensor: shape=(), dtype=float64, numpy=36.76225045>, 'blue_p50': <tf.Tensor: shape=(), dtype=float64, numpy=2568.0>, 'green_p50': <tf.Tensor: shape=(), dtype=float64, numpy=2918.0>, 'nir_p50': <tf.Tensor: shape=(), dtype=float64, numpy=5516.0>, 'nira_p50': <tf.Tensor: shape=(), dtype=float64, numpy=5707.0>, 're1_p50': <tf.Tensor: shape=(), dtype=float64, numpy=3325.0>, 're2_p50': <tf.Tensor: shape=(), dtype=float64, numpy=5076.0>, 're3_p50': <tf.Tensor: shape=(), dtype=float64, numpy=5609.0>, 'red_p50': <tf.Tensor: shape=(), dtype=float64, numpy=2902.0>, 'swir1_p50': <tf.Tensor: shape=(), dtype=float64, numpy=3671.0>, 'swir2_p50': <tf.Tensor: shape=(), dtype=float64, numpy=2688.0>, 'VV_p50': <tf.Tensor: shape=(), dtype=float64, numpy=-5.508221>, 'VH_p50': <tf.Tensor: shape=(), dtype=float64, numpy=-12.995374>}\n",
      "Target: tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 14:36:23.182952: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sq5CbyAneBVF"
   },
   "source": [
    "Let's batch the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BmA4ahKreBVF"
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDAzKm5ZeBVF"
   },
   "source": [
    "## Feature preprocessing with Keras layers\n",
    "\n",
    "\n",
    "All features are continuous numerical features:\n",
    "\n",
    "For each of these features, we will use a `Normalization()` layer to make sure the mean\n",
    "of each feature is 0 and its standard deviation is 1.\n",
    "\n",
    "Below, we define a utility function to do that operation:\n",
    "\n",
    "- `encode_numerical_feature` to apply featurewise normalization to numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Ql6vYlbpeBVF"
   },
   "outputs": [],
   "source": [
    "\n",
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = layers.Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JD9kq8_xeBVF"
   },
   "source": [
    "## Build a model\n",
    "\n",
    "With this done, we can create our end-to-end model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckV2BfdIJj-P"
   },
   "source": [
    "### Adaptative Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "PtSTXvpWJi-6"
   },
   "outputs": [],
   "source": [
    "class AdaptiveLearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, initial_learning_rate, decay_steps, decay_rate):\n",
    "        self.initial_learning_rate = tf.cast(initial_learning_rate, tf.float32)\n",
    "        self.decay_steps = tf.cast(decay_steps, tf.float32)\n",
    "        self.decay_rate = tf.cast(decay_rate, tf.float32)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)  # Ensure step is also float32\n",
    "        return self.initial_learning_rate * tf.math.pow(self.decay_rate, (step / self.decay_steps))\n",
    "\n",
    "\n",
    "# Example usage\n",
    "initial_learning_rate = 0.001\n",
    "decay_steps = 1000\n",
    "decay_rate = 0.96\n",
    "\n",
    "lr_schedule = AdaptiveLearningRateScheduler(initial_learning_rate, decay_steps, decay_rate)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',    # Metric to monitor\n",
    "    patience=1000,           # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ymj2a0BveBVF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 13:50:26.666407: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-31 13:50:26.700524: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-31 13:50:26.732850: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-31 13:50:26.764712: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-31 13:50:26.796204: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-31 13:50:26.827322: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-31 13:50:26.858635: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-31 13:50:26.890213: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-31 13:50:26.922309: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-31 13:50:26.953802: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-31 13:50:26.985512: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-31 13:50:27.017158: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-31 13:50:27.048362: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-31 13:50:27.079596: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    " # Numerical features\n",
    "lon = keras.Input(shape=(1,), name=\"lon\")\n",
    "lat = keras.Input(shape=(1,), name=\"lat\")\n",
    "blue_p50 = keras.Input(shape=(1,), name=\"blue_p50\")\n",
    "green_p50 = keras.Input(shape=(1,), name=\"green_p50\")\n",
    "nir_p50 = keras.Input(shape=(1,), name=\"nir_p50\")\n",
    "nira_p50 = keras.Input(shape=(1,), name=\"nira_p50\")\n",
    "re1_p50 = keras.Input(shape=(1,), name=\"re1_p50\")\n",
    "re2_p50 = keras.Input(shape=(1,), name=\"re2_p50\")\n",
    "re3_p50 = keras.Input(shape=(1,), name=\"re3_p50\")\n",
    "red_p50 = keras.Input(shape=(1,), name=\"red_p50\")\n",
    "swir1_p50 = keras.Input(shape=(1,), name=\"swir1_p50\")\n",
    "swir2_p50 = keras.Input(shape=(1,), name=\"swir2_p50\")\n",
    "VV_p50 = keras.Input(shape=(1,), name=\"VV_p50\")\n",
    "VH_p50 = keras.Input(shape=(1,), name=\"VH_p50\")\n",
    "\n",
    "all_inputs = [\n",
    "    lon,\n",
    "    lat,\n",
    "    blue_p50,\n",
    "    green_p50,\n",
    "    nir_p50,\n",
    "    nira_p50,\n",
    "    re1_p50,\n",
    "    re2_p50,\n",
    "    re3_p50,\n",
    "    red_p50,\n",
    "    swir1_p50,\n",
    "    swir2_p50,\n",
    "    VV_p50,\n",
    "    VH_p50\n",
    "]\n",
    "\n",
    "# Integer categorical features\n",
    "lon_encoded = encode_numerical_feature(lon, \"lon\", train_ds)\n",
    "lat_encoded = encode_numerical_feature(lat, \"lat\", train_ds)\n",
    "blue_p50_encoded = encode_numerical_feature(blue_p50, \"blue_p50\", train_ds)\n",
    "green_p50_encoded = encode_numerical_feature(green_p50, \"green_p50\", train_ds)\n",
    "nir_p50_encoded = encode_numerical_feature(nir_p50, \"nir_p50\", train_ds)\n",
    "nira_p50_encoded = encode_numerical_feature(nira_p50, \"nira_p50\", train_ds)\n",
    "re1_p50_encoded = encode_numerical_feature(re1_p50, \"re1_p50\", train_ds)\n",
    "re2_p50_encoded = encode_numerical_feature(re2_p50, \"re2_p50\", train_ds)\n",
    "re3_p50_encoded = encode_numerical_feature(re3_p50, \"re3_p50\", train_ds)\n",
    "red_p50_encoded = encode_numerical_feature(red_p50, \"red_p50\", train_ds)\n",
    "swir1_p50_encoded = encode_numerical_feature(swir1_p50, \"swir1_p50\", train_ds)\n",
    "swir2_p50_encoded = encode_numerical_feature(swir2_p50, \"swir2_p50\", train_ds)\n",
    "VV_p50_encoded = encode_numerical_feature(VV_p50, \"VV_p50\", train_ds)\n",
    "VH_p50_encoded = encode_numerical_feature(VH_p50, \"VH_p50\", train_ds)\n",
    "\n",
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        lon_encoded,\n",
    "        lat_encoded,\n",
    "        blue_p50_encoded,\n",
    "        green_p50_encoded,\n",
    "        nir_p50_encoded,\n",
    "        nira_p50_encoded,\n",
    "        re1_p50_encoded,\n",
    "        re2_p50_encoded,\n",
    "        re3_p50_encoded,\n",
    "        red_p50_encoded,\n",
    "        swir1_p50_encoded,\n",
    "        swir2_p50_encoded,\n",
    "        VV_p50_encoded,\n",
    "        VH_p50\n",
    "    ]\n",
    ")\n",
    "x1 = layers.Dense(64, activation=\"relu\")(all_features)\n",
    "x1 = layers.Dropout(0.5)(x1)\n",
    "x2 = layers.Dense(64, activation=\"relu\")(all_features)\n",
    "x2 = layers.Dropout(0.5)(x2)\n",
    "x3 = layers.Dense(64, activation=\"relu\")(all_features)\n",
    "x3 = layers.Dropout(0.5)(x3)\n",
    "x4 = layers.Dense(64, activation=\"relu\")(all_features)\n",
    "x4 = layers.Dropout(0.5)(x4)\n",
    "x5 = layers.Dense(64, activation=\"relu\")(all_features)\n",
    "x5 = layers.Dropout(0.5)(x5)\n",
    "x6 = layers.Dense(64, activation=\"relu\")(all_features)\n",
    "x6 = layers.Dropout(0.5)(x6)\n",
    "x7 = layers.Dense(64, activation=\"relu\")(all_features)\n",
    "x7 = layers.Dropout(0.5)(x7)\n",
    "x8 = layers.Dense(64, activation=\"relu\")(all_features)\n",
    "x8 = layers.Dropout(0.5)(x3)\n",
    "\n",
    "x1 = layers.concatenate((x1,x2))\n",
    "x2 = layers.concatenate((x3,x4))\n",
    "x3 = layers.concatenate((x5,x6))\n",
    "x4 = layers.concatenate((x6,x7))\n",
    "\n",
    "x1 = layers.Dense(128, activation=\"relu\")(x1)\n",
    "x1 = layers.Dropout(0.5)(x1)\n",
    "x2 = layers.Dense(128, activation=\"relu\")(x2)\n",
    "x2 = layers.Dropout(0.5)(x2)\n",
    "x3 = layers.Dense(128, activation=\"relu\")(x3)\n",
    "x3 = layers.Dropout(0.5)(x3)\n",
    "x4 = layers.Dense(128, activation=\"relu\")(x4)\n",
    "x4 = layers.Dropout(0.5)(x4)\n",
    "\n",
    "x1 = layers.concatenate((x1,x2))\n",
    "x2 = layers.concatenate((x3,x4))\n",
    "\n",
    "x1 = layers.Dense(256, activation=\"relu\")(x1)\n",
    "x1 = layers.Dropout(0.5)(x1)\n",
    "x2 = layers.Dense(256, activation=\"relu\")(x2)\n",
    "x2 = layers.Dropout(0.5)(x2)\n",
    "\n",
    "x = layers.concatenate((x1,x2))\n",
    "\n",
    "x = layers.Dense(512, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "_HvO0WjlKlEE"
   },
   "outputs": [],
   "source": [
    "model.compile(tf.keras.optimizers.Adam(),\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Vgh8IOIeBVG"
   },
   "source": [
    "Let's visualize our connectivity graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WCmSLEdteBVG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEE1MDI6eBVG"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwZY5K85eBVG",
    "outputId": "aea72e96-b127-4ec8-d138-7fece5fb4c58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data=val_ds, callbacks=[early_stopping], verbose=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "rFoNqK27OXa3"
   },
   "source": [
    "model.save('StructData_Model0.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QWLXxzCeBVG"
   },
   "source": [
    "## Inference on new data\n",
    "\n",
    "To get a prediction for a new sample, you can simply call `model.predict()`. There are\n",
    "just two things you need to do:\n",
    "\n",
    "1. wrap scalars into a list so as to have a batch dimension (models only process batches\n",
    "of data, not single samples)\n",
    "2. Call `convert_to_tensor` on each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "XejVoyJN4_cn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('StructData_Model0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Dh_acIa5DQ3"
   },
   "source": [
    "sample = {\n",
    "    \"age\": 60,\n",
    "    \"sex\": 1,\n",
    "    \"cp\": 1,\n",
    "    \"trestbps\": 145,\n",
    "    \"chol\": 233,\n",
    "    \"fbs\": 1,\n",
    "    \"restecg\": 2,\n",
    "    \"thalach\": 150,\n",
    "    \"exang\": 0,\n",
    "    \"oldpeak\": 2.3,\n",
    "    \"slope\": 3,\n",
    "    \"ca\": 0,\n",
    "    \"thal\": \"fixed\",\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = model.predict(input_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOlj8k3s6JBX"
   },
   "source": [
    "### Test Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iklz1arz6Njd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y = dataframe_test['TARGET']\n",
    "X = dict(dataframe_test.drop(['TARGET'], axis=1))\n",
    "\n",
    "pred = model.predict(X).astype(int)\n",
    "pred = pred.reshape(-1)\n",
    "accuracy_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2k7F11yzfuE"
   },
   "outputs": [],
   "source": [
    "Kenya = pd.read_csv(\"Kenya_testing.csv\")\n",
    "Spain =  pd.read_csv(\"Spain_validation.csv\")\n",
    "VNM =  pd.read_csv(\"VNM_testing.csv\")\n",
    "VNM.rename(columns={'Lon': 'lon', 'Lat': 'lat'}, inplace=True) # It's to allign with the other two sources.\n",
    "\n",
    "dataframe = pd.concat([Kenya, Spain, VNM], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbVoqZLNwoV1"
   },
   "outputs": [],
   "source": [
    "#    dataframe = dataframe.copy()\n",
    "#    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe)))\n",
    "#    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "#    return ds\n",
    "ds = dict(dataframe)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tDSy0hpPxixM",
    "outputId": "00962ca4-b029-4a46-8174-7b712f018af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(ds).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StwRwh-w0cY4",
    "outputId": "422ed4bb-944d-4b7e-8d25-95461b8c56cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yWTvWJU25Ztk",
    "outputId": "6fde1648-0ea0-476b-f958-2b5f8e2e701c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "senWZyDt5bQ9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
